{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML T-Generation Занятие 4: Классификация.\n",
    "# Логрегрессия. KNN. Метрики.\n",
    "\n",
    "Автор: Гаркавый Андрей (andrewgarkavyy@gmail.com)\n",
    "\n",
    "\n",
    "## 0. План\n",
    "\n",
    "1. Логистическая регрессия: теория\n",
    "\n",
    "2. Логистическая регрессия: практика \n",
    "\n",
    "3. Сравнение с KNN\n",
    "\n",
    "3. Precision/Recall\n",
    "\n",
    "4. ROC-AUC\n",
    "\n",
    "5. Небинарная классификация\n",
    "\n",
    "## 1. Логистическая регрессия: теория\n",
    "(в названии регрессия, но на самом деле это алгоритм классификации)\n",
    "\n",
    "\n",
    "Рассмотрим **задачу классификации**. Для простоты рассматрим бинарную классификацию: для каждого примера в обучающей выборке указан его класс: 0 или 1.\n",
    "\n",
    "Нам нужно по признакам научиться восстанавливать класс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже умеем предсказывать числа (решать задачу регрессии) с помощью модели Линейной регрессии. Самое простое - использовать её для предсказания классов? А именно, будем просто предсказывать эти 0 и 1.\n",
    "\n",
    "Тут даже понятно, как решать по предсказанному числу, какой это класс - если больше 0.5, то класс 1, иначе класс 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот подход работает, но он несколько противоестественный: предположим, наша модель предсказала для объекта класса 1 значение 2. За такое предсказание она получит такой же штраф, как за предсказание 0: $(2-1)^2 = (0-1)^2$.\n",
    "\n",
    "Давайте попробуем придумать более естественную функцию потерь. Естественно считать, что чем больше предсказание нашей модели, тем сильнее она уверена, что объект принадлежит классу 1. Давайте попробуем интерпретировать предсказание модели как вероятность того, что объект принадлежит классу 1.\n",
    "\n",
    "Модель (теоретически) может выдавать значения от минус до плюс бесконечности, значит нам нужно научиться превращать интервал $(-\\infty, \\infty)$ в интервал $(0, 1)$. Такие функции называют сигмоидами -- потому что они напоминают внешне букву s. Наиболее стандартная такая функция называется логистической функцией и выглядит так:\n",
    "$$\n",
    " \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сигмоидная функция\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbf6e2fa850>]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m9f0116cf50\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"75.75767\" xlink:href=\"#m9f0116cf50\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- −4 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(68.386577 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"136.630398\" xlink:href=\"#m9f0116cf50\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- −2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(129.259304 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.503125\" xlink:href=\"#m9f0116cf50\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(194.321875 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"258.375852\" xlink:href=\"#m9f0116cf50\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2 -->\n      <g transform=\"translate(255.194602 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.24858\" xlink:href=\"#m9f0116cf50\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 4 -->\n      <g transform=\"translate(316.06733 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m17a9afa51e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m17a9afa51e\" y=\"216.097307\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 219.896526)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m17a9afa51e\" y=\"176.026384\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 179.825603)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m17a9afa51e\" y=\"135.955461\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 139.75468)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m17a9afa51e\" y=\"95.884539\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 99.683757)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m17a9afa51e\" y=\"55.813616\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(7.2 59.612834)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m17a9afa51e\" y=\"15.742693\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(7.2 19.541912)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#p57cc592d02)\" d=\"M 45.321307 214.756364 \nL 48.395687 214.614892 \nL 51.470067 214.458618 \nL 54.544447 214.28602 \nL 57.618827 214.095426 \nL 60.693208 213.885 \nL 63.767588 213.652728 \nL 66.841968 213.396401 \nL 69.916348 213.113603 \nL 72.990728 212.801688 \nL 76.065108 212.457767 \nL 79.139489 212.078687 \nL 82.213869 211.661014 \nL 85.288249 211.201014 \nL 88.362629 210.694631 \nL 91.437009 210.137474 \nL 94.511389 209.524796 \nL 97.58577 208.851482 \nL 100.66015 208.112034 \nL 103.73453 207.300561 \nL 106.80891 206.410778 \nL 109.88329 205.436003 \nL 112.95767 204.369169 \nL 116.032051 203.202837 \nL 119.106431 201.929228 \nL 122.180811 200.540263 \nL 125.255191 199.027615 \nL 128.329571 197.382783 \nL 131.403951 195.597183 \nL 134.478332 193.662257 \nL 137.552712 191.569607 \nL 140.627092 189.31115 \nL 143.701472 186.879297 \nL 146.775852 184.267149 \nL 149.850232 181.468724 \nL 152.924613 178.479188 \nL 155.998993 175.295103 \nL 159.073373 171.914681 \nL 162.147753 168.338028 \nL 165.222133 164.567372 \nL 168.296513 160.607274 \nL 171.370894 156.464785 \nL 174.445274 152.149559 \nL 177.519654 147.6739 \nL 180.594034 143.052735 \nL 183.668414 138.3035 \nL 186.742794 133.445946 \nL 189.817175 128.50186 \nL 192.891555 123.494705 \nL 195.965935 118.449192 \nL 199.040315 113.390808 \nL 202.114695 108.345295 \nL 205.189075 103.33814 \nL 208.263456 98.394054 \nL 211.337836 93.5365 \nL 214.412216 88.787265 \nL 217.486596 84.1661 \nL 220.560976 79.690441 \nL 223.635356 75.375215 \nL 226.709737 71.232726 \nL 229.784117 67.272628 \nL 232.858497 63.501972 \nL 235.932877 59.925319 \nL 239.007257 56.544897 \nL 242.081637 53.360812 \nL 245.156018 50.371276 \nL 248.230398 47.572851 \nL 251.304778 44.960703 \nL 254.379158 42.52885 \nL 257.453538 40.270393 \nL 260.527918 38.177743 \nL 263.602299 36.242817 \nL 266.676679 34.457217 \nL 269.751059 32.812385 \nL 272.825439 31.299737 \nL 275.899819 29.910772 \nL 278.974199 28.637163 \nL 282.04858 27.470831 \nL 285.12296 26.403997 \nL 288.19734 25.429222 \nL 291.27172 24.539439 \nL 294.3461 23.727966 \nL 297.42048 22.988518 \nL 300.494861 22.315204 \nL 303.569241 21.702526 \nL 306.643621 21.145369 \nL 309.718001 20.638986 \nL 312.792381 20.178986 \nL 315.866761 19.761313 \nL 318.941142 19.382233 \nL 322.015522 19.038312 \nL 325.089902 18.726397 \nL 328.164282 18.443599 \nL 331.238662 18.187272 \nL 334.313042 17.955 \nL 337.387423 17.744574 \nL 340.461803 17.55398 \nL 343.536183 17.381382 \nL 346.610563 17.225108 \nL 349.684943 17.083636 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p57cc592d02\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "x = np.linspace(-5, 5, 100)\n",
    "plt.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, можно считать, что если наша модель предсказывает для объекта $x$ число $f(x)$ это означает, что $p_x$ = $\\sigma(f(x))$ - вероятность того, что объект принадлежит к классу 1.\n",
    "\n",
    "Для данного примера класса 1 вероятность того, что наша модель угадала правльно равна $p_x$, для примера класса 0 эта вероятность равна $1-p_x$. \n",
    "\n",
    "Давайте посчитаем вероятность того, что наша модель \"угадает\" значение всех элементов:\n",
    "\n",
    "$$\\prod_{x \\in 1} p_x \\prod_{x \\in 0} (1-p_x)$$\n",
    "\n",
    "Мы хотим максимизировать эту вероятность.\n",
    "\n",
    "Работать с произведением неудобно, поэтому возьмем логарифм:\n",
    "\n",
    "$$\\sum_{x \\in 1} \\ln(p_x)  + \\sum_{x \\in 0} \\ln(1-p_x)$$\n",
    "\n",
    "Из этого бы получилась отличная функция потерь, вот только функцию потерь мы хотим минимизировать, а эту функцию нужно максимизировать для лучшего результата. Поэтому умножим её на минус один.\n",
    "\n",
    "$$Logloss = -\\sum_{x \\in 1} \\ln(p_x)  - \\sum_{x \\in 0} \\ln(1-p_x)$$\n",
    "\n",
    "Эта функция потерь называется Logloss. Оказывается, что её довольно просто оптимизировать.\n",
    "\n",
    "Описанный нами алгоритм называется **Логистическая регрессия**. Это алгоритм бинарной классификации (а не регрессии, пусть название вас не путает):\n",
    "\n",
    "1) алгоритм предсказывает $f(x)$ по модели линейной регрессии ($f(x) = a_0 + a_1 x_1 + \\ldots a_n x_n$)\n",
    "\n",
    "2) от каждого значения считается сигмоида для предсказания вероятности ($p_x = \\sigma(f(x)) = \\frac{1}{1 + e^{f(x)}}$)\n",
    "\n",
    "3) по этим вероятностям считается Logloss ($Logloss = -\\sum_{x \\in 1} \\ln(p_x)  - \\sum_{x \\in 0} \\ln(1-p_x)$)\n",
    "\n",
    "4) параметры для модели подбираются так, чтобы именно этот логлосс и был минимален\n",
    "\n",
    "5) предсказание после этого делается так: если вероятность больше 0.5 (то есть f(x) > 0), то это класс 1, иначе это класс 0.\n",
    "\n",
    "Можно также представить, что вы пытаетесь разделить точки двух разных цветов с помощью плоскости. Все, точки оказавшиеся в одном полупространстве, вы предсказываете как класс 0, а в другом - как класс 1.\n",
    "\n",
    "# 2. Логистическая регрессия: практика\n",
    "\n",
    "Как обычно, эта модель уже есть в библиотеке sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем работать с датасетом, содержащим данные о порядка 18 тысячах звезд, некоторые из которых являются пульсарами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pulsar_stars.csv')\n",
    "\n",
    "X = data.drop(columns=['target_class']) # убираем столбец с целевой переменной\n",
    "y = data['target_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Mean of the integrated profile  \\\n",
       "0                       140.562500   \n",
       "1                       102.507812   \n",
       "2                       103.015625   \n",
       "3                       136.750000   \n",
       "4                        88.726562   \n",
       "\n",
       "    Standard deviation of the integrated profile  \\\n",
       "0                                      55.683782   \n",
       "1                                      58.882430   \n",
       "2                                      39.341649   \n",
       "3                                      57.178449   \n",
       "4                                      40.672225   \n",
       "\n",
       "    Excess kurtosis of the integrated profile  \\\n",
       "0                                   -0.234571   \n",
       "1                                    0.465318   \n",
       "2                                    0.323328   \n",
       "3                                   -0.068415   \n",
       "4                                    0.600866   \n",
       "\n",
       "    Skewness of the integrated profile   Mean of the DM-SNR curve  \\\n",
       "0                            -0.699648                   3.199833   \n",
       "1                            -0.515088                   1.677258   \n",
       "2                             1.051164                   3.121237   \n",
       "3                            -0.636238                   3.642977   \n",
       "4                             1.123492                   1.178930   \n",
       "\n",
       "    Standard deviation of the DM-SNR curve  \\\n",
       "0                                19.110426   \n",
       "1                                14.860146   \n",
       "2                                21.744669   \n",
       "3                                20.959280   \n",
       "4                                11.468720   \n",
       "\n",
       "    Excess kurtosis of the DM-SNR curve   Skewness of the DM-SNR curve  \\\n",
       "0                              7.975532                      74.242225   \n",
       "1                             10.576487                     127.393580   \n",
       "2                              7.735822                      63.171909   \n",
       "3                              6.896499                      53.593661   \n",
       "4                             14.269573                     252.567306   \n",
       "\n",
       "   target_class  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mean of the integrated profile</th>\n      <th>Standard deviation of the integrated profile</th>\n      <th>Excess kurtosis of the integrated profile</th>\n      <th>Skewness of the integrated profile</th>\n      <th>Mean of the DM-SNR curve</th>\n      <th>Standard deviation of the DM-SNR curve</th>\n      <th>Excess kurtosis of the DM-SNR curve</th>\n      <th>Skewness of the DM-SNR curve</th>\n      <th>target_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>140.562500</td>\n      <td>55.683782</td>\n      <td>-0.234571</td>\n      <td>-0.699648</td>\n      <td>3.199833</td>\n      <td>19.110426</td>\n      <td>7.975532</td>\n      <td>74.242225</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>102.507812</td>\n      <td>58.882430</td>\n      <td>0.465318</td>\n      <td>-0.515088</td>\n      <td>1.677258</td>\n      <td>14.860146</td>\n      <td>10.576487</td>\n      <td>127.393580</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>103.015625</td>\n      <td>39.341649</td>\n      <td>0.323328</td>\n      <td>1.051164</td>\n      <td>3.121237</td>\n      <td>21.744669</td>\n      <td>7.735822</td>\n      <td>63.171909</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>136.750000</td>\n      <td>57.178449</td>\n      <td>-0.068415</td>\n      <td>-0.636238</td>\n      <td>3.642977</td>\n      <td>20.959280</td>\n      <td>6.896499</td>\n      <td>53.593661</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>88.726562</td>\n      <td>40.672225</td>\n      <td>0.600866</td>\n      <td>1.123492</td>\n      <td>1.178930</td>\n      <td>11.468720</td>\n      <td>14.269573</td>\n      <td>252.567306</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обычно, разбиваем данные на тренировочную и тестовую части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели классификации происходит ровно так же, как и модели регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на первый параметр $С$ - он отвечает за регуляризацию: меньшие значения $С$ соответствуют большим штрафам за \"усложнение\" модели.\n",
    "\n",
    "Предсказание происходит тоже ровно так же: получаем целевую функцию (класс) по методу predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но в отличие от регрессии у моделей классификации часто есть еще и возможность предсказать вероятность принадлежности классу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.99380714, 0.00619286],\n",
       "       [0.30027636, 0.69972364],\n",
       "       [0.98309977, 0.01690023],\n",
       "       ...,\n",
       "       [0.9980718 , 0.0019282 ],\n",
       "       [0.99352395, 0.00647605],\n",
       "       [0.97040427, 0.02959573]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "y_pred_proba = log_reg.predict_proba(X_test)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Сравнение с KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как понять, хороший ли получился результат? Самое простое - сделать как в регрессии, сравнить используемую метрику на нашей модели и на какой-нибудь другой. Давайте возьмем три модели:\n",
    "\n",
    "1) Предсказать всем 0 (все равно звезда почти всегда не пульсар)\n",
    "\n",
    "2) Лог. регрессия\n",
    "\n",
    "3) KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({0: 11375, 1: 1153})"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оказывается, звезда в 10 раз чаще не пульсар, чем пульсар (по крайней мере в нашем датасете)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "y_pred_const = np.zeros(len(X_test)) \n",
    "y_pred_proba_const = y_pred_const\n",
    "y_pred_proba_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.00619286, 0.69972364, 0.01690023, ..., 0.0019282 , 0.00647605,\n",
       "       0.02959573])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_proba_log_reg = log_reg.predict_proba(X_test)[:, 1]  # оставили только второй столбец\n",
    "y_pred_proba_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось обучить модель KNN. Вы уже ее писали ее на первом занятии, но давайте вспомним, что это за алгоритм классификации.\n",
    "\n",
    "**Метод K ближайших соседей (K Nearest Neighbors)** заключается в том, что мы рассматриваем каждый объект как точку в $n$-мерном пространстве, где $n$ - это число признаков. Тогда чтобы предсказать класс какой-нибудь новой точки, нам нужно просто найти $K$ ближайших к ней объектов в тренировочной части и выбрать самый популярный класс среди них.\n",
    "\n",
    "Естественно, эта модель тоже уже написана в sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5) # выберем K=5 например\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. ])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_proba_knn = knn.predict_proba(X_test)[:, 1]  # оставили только второй столбец\n",
    "y_pred_proba_knn[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот алгоритм не заточен под предсказание вероятности принадлежности к классу, и делает это очень наивно и грубо: если среди $K$ соседей ровно $T$ принадлежат классу 1, то вероятность принадлежности классу 1 равна $\\frac{T}{K}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь осталось сравнить наши предсказанные результаты. Например, раз мы учили лог. регрессию на logloss, давайте сравним его (помните, для регрессии же мы сравнивали MSE).\n",
    "\n",
    "**Обязательное задание 1**: реализуйте logloss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.8134107167600364"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "# Реализуйте функцию\n",
    "# Как обычно, чем короче, тем лучше\n",
    "\n",
    "def logloss(y_real, y_pred_proba):\n",
    "    return np.sum(-np.log(y_pred_proba[index]) for index, elem in enumerate(y_real) if elem == 1) + np.sum(-np.log((1 - y_pred_proba[index])) for index, elem in enumerate(y_real) if elem == 0)\n",
    "\n",
    "logloss([1, 1, 0, 1], [0.5, 0.5, 0.4, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Logloss = 2.3842290820345555\nReal answer = 2.384229082034556\n"
     ]
    }
   ],
   "source": [
    "# Тест:\n",
    "print('Logloss =', logloss(np.array([0, 1, 0, 1, 0]), np.array([0.2, 0.8, 0.4, 0.6, 0.6])))\n",
    "print('Real answer =', -(np.log(0.8) + np.log(0.8) + np.log(0.6) + np.log(0.6) + np.log(0.4)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, чему равен лог лосс на разных моделях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "logloss(y_test, y_pred_proba_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша модель \"все вероятности равны 0\" не работает: если мы угадали все классы, то мы действительно получаем логлосс 0. Но если мы хотя бы раз ошиблись, то мы получим минус логарифм от 0, то есть бесконечность. Предсказывать вероятность в логлоссе как прямо 0 никогда нельзя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "414.55443397088015"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "logloss(y_test, y_pred_proba_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "logloss(y_test, y_pred_proba_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С KNN получилась такая же проблема: слишком много вероятностей, равных 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, Logloss так себе подходит для сравнения результатов классификации - у наивных моделей там часто возникают бесконечности, да и само число ничего конкретного не значит. В MSE мы хотя бы примерно понимали, что такое средний квадрат отклонений, а тут это абсолютно не говорящее ни о чем число."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте лучше посчитаем **точность** - accuracy. То есть просто **долю объектов с правильно предсказанным классом**.\n",
    "\n",
    "(вообще называеть ее \"точность\" - плохая идея, потому что у другой метрики, которую мы сегодня рассмотрим (precision) на русский ровно тот же перевод)\n",
    "\n",
    "**Обязательное задание 2:** реализуйте функцию accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте функцию\n",
    "# Как обычно, чем короче, тем лучше\n",
    "\n",
    "def accuracy(y_real, y_pred):\n",
    "    return np.sum(1 for index, elem in enumerate(y_real) if elem == y_pred[index]) / len(y_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.6\nReal answer = 0.6\n"
     ]
    }
   ],
   "source": [
    "# Тест:\n",
    "print('Accuracy =', accuracy(np.array([0, 1, 0, 1, 0]), np.array([0, 0, 0, 1, 1])))\n",
    "print('Real answer =', 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, чему равна accuracy на разных моделях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9094972067039107"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "accuracy(y_test, y_pred_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9791433891992551"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "accuracy(y_test, y_pred_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9733705772811918"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "accuracy(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы явно видим, что точность константного предсказания (все звезды - не пульсары) - это уже 90%. Действительно, в тестовой части тоже каждая только примерно 10-я звезда является пульсаром.\n",
    "\n",
    "Причем точности и Лог. регрессии, и KNN - значительно выше, это чуть больше 97%. На конкретно моем разбиении на train и test получилось, что accuracy у лог. регрессии все-таки лучше, но пока неясно, это погрешность и разницы особое нет, или все-таки есть значительнон преимущество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь сразу видна большая проблема: из-за несбалансированности классов (9 к 1) accuracy наивного предсказания легко набирает сразу 90%. Очень тяжело сравнивать модели по метрике, которая у всех нормальных моделей находится на маленьком отрезке $[0.9, 1.0]$. А представьте, что пульсаров было бы еще меньше: один из сотни звезд. А такое в жизни бывает очень часто - например в рекламе вам нужно понять, сделает ли юзер клик по этому баннеру, и этих кликов по баннеру в данных встречается очень и очень мало, обычно все-таки клика нет. Поэтому модель \"всегда нет клика\" будет сразу набирать 99% accuracy.\n",
    "\n",
    "Для таких дико несбалансированных данных нужны какие-то другие, более говорящие метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Precision / Recall\n",
    "\n",
    "Чтобы обойти эту проблему часто рассматривают две другие метрики: **precision** (точность) и **recall** (полнота). Пусть у нас все еще бинарная классификация, и класса 0 очень много, а вот класса 1 - поменьше.\n",
    "\n",
    "Точность -- доля объектов класса 1 среди всех объектов, которые наш классификатор отнес к классу 1.\n",
    "\n",
    "Полнота -- доля объектов класса 1, которые наш классификатор определил правильно среди всех объектов класса 1:\n",
    "\n",
    "**Обязательное задание 3:** реализовать две эти функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализуйте функцию\n",
    "# Как обычно, чем короче, тем лучше\n",
    "\n",
    "def precision(y_real, y_pred):\n",
    "    pass\n",
    "\n",
    "def recall(y_real, y_pred):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_pred_const))\n",
    "print(recall(y_test, y_pred_const))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_pred_log_reg))\n",
    "print(recall(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_pred_knn))\n",
    "print(recall(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие мы получили результаты? \n",
    "\n",
    "1) Константное предсказание \"всегда говори 0\" получает nan точность (это доля пульсаров среди предсказанных пульсаров, а мы ни один решили не предсказывать) и 0 полноту (это доля пульсаров, которые мы нашли, а мы ничего не нашли).\n",
    "\n",
    "2) Среди предсказанных с помощью KNN и Лог. регрессии пульсаров 90%-94% звезд действительно являются пульсарами.\n",
    "\n",
    "3) А вот среди всех пульсаров наши модели нашли только 78%-80% пульсаров.\n",
    "\n",
    "4) В целом получается, что модели предсказывают пульсары скорее точно, но при этом много еще не находят (точность больше полноты)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто для того, чтобы учесть несбалансированность нашего множества, мы можем задать разный вес для разных классов. \n",
    "Например, у Лог. регрессии есть параметр class_weight, который принимает словарь, сопоставляющий каждому классу его вес.\n",
    "\n",
    "При этос вес участвует в Логлоссе - каждое слагаемое с реальным классом 1 просто умножается на вес класса 1, а слагаемое с реальным классом 0 просто умножается на вес класса 0.\n",
    "\n",
    "По сути эти веса значат то, насколько важнее предсказать хорошо класс 0 или класс 1.\n",
    "\n",
    "$$Logloss = -w_1 \\sum_{x \\in 1} \\ln(p_x)  -w_0 \\sum_{x \\in 0} \\ln(1-p_x)$$\n",
    "\n",
    "В изначальных данных у нас почти все звезды были пульсарами (класса 0), и их качество предсказания было гораздо важнее, давайте сбалансируем веса (так половина веса будет приходить из обычных звезд и половина веса из пульсаров)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_w = LogisticRegression(class_weight = {0: 1, 1: 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 1, 1: 10}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_w.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_w = log_reg_w.predict(X_test)\n",
    "y_pred_proba_w = log_reg_w.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(precision(y_test, y_pred_w))\n",
    "print(recall(y_test, y_pred_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность классификатора заметно упала -- он стал чаще говорить \"1\" (так как ошибиться с непульсаром теперь не так страшно), но зато заметно возросла полнота. Хорошо это или плохо -- зависит от того, как мы собираемся использовать наш классификатор.\n",
    "\n",
    "Если для нас очень важно не пропустить ни одного пульсара (а если мы какую-то звезду тоже назовем пульсаром по ошибке, то не очень страшно) нам нужно растить полноту -- это возможно, например, если потом на выбранные звезды посмотрят в радиотелескоп и уточнят предсказание.\n",
    "\n",
    "А может быть, что для нас важно не назвать пульсаром звезду, которая им не является (например, ко всем потенциальным пульсарам мы отправим дорогой исследовательский зонд -- не страшно пропустить какие-то, но очень обидно отправить зонд к не-пульсару).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для полноты картины введем еще два определения:\n",
    "    - ошибка первого рода (Type I error, false positive) - ситуация, когда наша модель отнесла объект класса 0 к классу 1\n",
    "    - ошибка второго рода (Type II error, false negative) - ситуация, когда наша модель отнесла объект класса 1 к классу 0\n",
    "    \n",
    "Аналогично правильные предсказания можно разделить на true positives и true negatives\n",
    "\n",
    "![Таблица](table.jpg)\n",
    "\n",
    "Как запомнить какая ошибка что: в сказке про мальчика, который кричал \"Волк!\" сначала описывается ошибка первого рода, а потом - второго.\n",
    "\n",
    "![Ошибки](errors.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обязательно задание 4:** запишите accuracy, precision и recall в терминах количества ошибок первого и второго рода (FP и FN) и количества правильных предсказаний (TP, TN).\n",
    "\n",
    "Accuracy = <..>\n",
    "\n",
    "Precision = <..>\n",
    "\n",
    "Recall = <..>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обязательное задание 5:** постройте график зависимости precision и recall от соотношения весов в графе в логистической регрессии.\n",
    "\n",
    "Пусть вес класса 0 будет всегда равен 1, переберите чему равен вес класса 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте график"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует метрика, объединяющая точность и полноту - их среднее гармоническое. Эта метрика называется $F_1$-мерой:\n",
    "\n",
    "$$ F_1 = \\frac{2* precision*recall}{precision+recall}$$\n",
    "\n",
    "**Обязательное задание 6:** добавьте на график еще и f1-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# постройте график"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ROC-AUC\n",
    "\n",
    "Продолжим изучать метрики бинарной классификации. Представим, что мы предсказали пульсары - но изучать их надо в каком-то порядке. В порядке уменьшения вероятности, что они пульсары.\n",
    "\n",
    "Надо как-то научить мерить, **насколько хорошо мы предсказали вероятности с точки зрения порядка**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте отсортируем все зведы по вероятности, что они пульсары. Если бы мы идеально предсказали пульсары, то сначала в этом списке идут исключительно не-пульсары, а потом исключительно пульсары.\n",
    "\n",
    "В реальности, конечно, там будут ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00616478, 0.72771847, 0.01724064, ..., 0.00216966, 0.0060361 ,\n",
       "       0.02493709])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(15985, 0.006164777162987372),\n",
       " (8188, 0.7277184665792835),\n",
       " (8157, 0.01724064255677232),\n",
       " (2589, 0.4509527875189887),\n",
       " (11909, 0.018097942970359673)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X_test.index, y_pred_proba))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13504, 1.3476068473818813e-08),\n",
       " (14049, 1.5600784261373386e-08),\n",
       " (16272, 2.7506187984215576e-08),\n",
       " (9529, 3.074788013156148e-08),\n",
       " (7472, 3.6892750037652856e-08)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_by_proba = sorted(list(zip(X_test.index, y_pred_proba)), key=lambda x: x[1])\n",
    "sorted_by_proba[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "results = [y_test[id] for id, proba in sorted_by_proba]\n",
    "print(results[:25])\n",
    "print(results[1000:1025])\n",
    "print(results[3000:3025])\n",
    "print(results[5000:5025])\n",
    "print(results[-25:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот мы отсортировали по вероятности принадлежности классу 1 - и действительно, сначала долго идут объекты класса 0, потом в какой-то момент начинают появляться пульсары, потом их все больше, и в конце остаются исключительно они (ну почему-то кроме последнего в моем случае).\n",
    "\n",
    "Датасайентисты очень любят рисовать ROС-кривую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "plt.figure(figsize=(7, 7))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, 'b', linewidth=3)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot([0, 0], [0, 1], 'k')\n",
    "plt.plot([1, 1], [0, 1], 'k')\n",
    "plt.plot([0, 1], [0, 0], 'k')\n",
    "plt.plot([0, 1], [1, 1], 'k')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((0, 1))\n",
    "plt.axis('equal')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У ROC-кривой в общем-то есть два определения.\n",
    "\n",
    "1) Вот у нас есть отсортированный по вероятности массив объектов. Нам нужно решить, где его разрезать на две части - все левые мы предскажем как класс 0, а правые как класс 1.\n",
    "\n",
    "Давайте для каждого возможного разреза просто посчитаемдве метрики и нарисуес график зависимости одной от другой:\n",
    "\n",
    "$$False\\space positive\\space rate = \\frac{FP}{FP + TN} = \\frac{FP}{size(0)}$$\n",
    "$$True\\space positive\\space rate = \\frac{TP}{TP + FN} = \\frac{TP}{size(1)}$$\n",
    "\n",
    "False positive rate - это доля предсказанных пульсаров среди реальных не-пульсаров.\n",
    "\n",
    "True positive rate - это доля предсказанных пульсаров среди реальных пульсаров.\n",
    "\n",
    "2) Наша кривая начинается в точке $(0, 0)$ и заканчивается в точке $(1, 1)$ (действительно, если мы все считаем не-пульсарами, то FPR = 0, TPR = 0, иначе FPR = 1, TPR = 1.\n",
    "\n",
    "Между ними она должна сделать несколько шагов вверх и вправо. Давайте просто идти слева направо по нашему и списку и каждый раз, когда попался объект класса 0, делать шаг вверх на $\\frac{1}{size(0)}$, а когда встретился объект класса 1, делать шаг вправо на $\\frac{1}{size(1)}$. Тогда мы в итоге обязательно придем из (0, 0) в (1, 1), и это получится ровно та же кривая.\n",
    "\n",
    "Действительно, каждый раз мы на самом деле просто перемещаем один объект из класса 0 в класс 1. Если его реальный класс равен 0, то TPR не изменился, а FPR увеличился на $\\frac{1}{size(0)}$. Если его реальный класс равен 1, то FPR не изменился, а TPR увеличился на $\\frac{1}{size(1)}$. Так что это то же самое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кривая это хорошо, но нам бы хотелось числовую метрику, которая бы говорила, насколько хорош получившийся из вероятностей порядок. Для это обычно берут **площадь под этой кривой** (Areas Under Curve - AUC), её еще называют ROC-AUC.\n",
    "\n",
    "Она не больше, чем 1, и чем выше и левее эта кривая, тем лучше.\n",
    "\n",
    "Практически всегда ROC AUC > 0.5 (иначе это легко поправить - надо просто перевернть все вероятности).\n",
    "\n",
    "ROC AUC позволяет глубоко оценивать качество предсказанных вероятностей. Accuracy, Precision и Recall работали только с самими предсказаниями классов, и никак вероятности не затрагивали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9748439516958035"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Небинарная классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы с вами рассматривали всё это время только задачу бинарной классификации, но что делать, когда классов болше, чем 2? На самом деле есть простой способ сводить любую классификацию к бинарной.\n",
    "\n",
    "Методика называется **One vs The Rest**. Давайте просто рассмотрим каждый класс как независимую бинарную классификацию, и будем предсказывать вероятности того, что этот элемент лежит в этом классе, или не лежит.\n",
    "\n",
    "Так про каждый класс мы получим вероятность, лежит ли в нем объект. Из них мы уже сможем выбрать лучший класс для этого объекта. А чтобы получить вероятности принадлежности каждому классу, эти числа еще нужно отнормировать, чтобы в сумме они давали 1.\n",
    "\n",
    "Давайте, например, рассмотрим датасет с циферками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "data = load_digits()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['data']\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти фичи - это на самом деле яркости пикселей вот такой картинки 8x8. Каждый пиксель - это число от 0 до 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_digit(features):\n",
    "    plt.imshow(features.reshape(8, 8), cmap=plt.cm.gray, vmax=16, interpolation='nearest')\n",
    "\n",
    "draw_digit(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_digit(X[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 178,\n",
       "         1: 182,\n",
       "         2: 177,\n",
       "         3: 183,\n",
       "         4: 181,\n",
       "         5: 182,\n",
       "         6: 181,\n",
       "         7: 179,\n",
       "         8: 174,\n",
       "         9: 180})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['target']\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В логистической регрессии уже по умолчанию включен мод One vs The Rest и она работает для нескольких классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 3, 7, 2, 1, 5, 2, 5, 2, 1, 8, 4, 0, 4, 2, 3, 7, 8, 8, 4, 3,\n",
       "       9, 7, 5, 6, 3, 5, 6, 3, 4, 9, 1, 4, 4, 6, 9, 4, 7, 6, 6, 9, 1, 3,\n",
       "       6, 1, 3, 0, 6, 5, 5, 1, 9, 5, 6, 0, 9, 0, 0, 1, 0, 4, 5, 2, 4, 5,\n",
       "       7, 0, 7, 5, 9, 5, 5, 4, 7, 0, 4, 5, 5, 9, 9, 0, 2, 3, 8, 0, 6, 4,\n",
       "       4, 9, 1, 2, 8, 3, 5, 2, 9, 0, 4, 4, 4, 3, 5, 3, 1, 3, 5, 9, 4, 2,\n",
       "       7, 7, 4, 4, 1, 9, 2, 7, 8, 7, 2, 6, 9, 4, 0, 7, 2, 7, 5, 8, 7, 5,\n",
       "       7, 9, 0, 6, 6, 4, 2, 8, 0, 9, 4, 6, 9, 9, 6, 9, 0, 5, 5, 6, 6, 0,\n",
       "       6, 4, 3, 9, 3, 8, 7, 2, 9, 0, 6, 5, 3, 6, 5, 8, 9, 8, 4, 2, 1, 3,\n",
       "       7, 7, 2, 2, 3, 9, 8, 0, 3, 2, 2, 5, 6, 9, 9, 4, 1, 2, 4, 2, 3, 6,\n",
       "       4, 8, 5, 9, 5, 7, 8, 9, 4, 8, 1, 5, 4, 4, 9, 6, 1, 8, 6, 0, 4, 5,\n",
       "       2, 7, 1, 6, 4, 5, 6, 0, 3, 2, 3, 6, 7, 1, 5, 1, 4, 7, 6, 5, 8, 5,\n",
       "       5, 1, 5, 2, 8, 8, 9, 8, 7, 6, 2, 2, 2, 3, 4, 8, 8, 3, 6, 0, 9, 7,\n",
       "       7, 0, 1, 0, 4, 5, 8, 5, 3, 6, 0, 4, 1, 0, 0, 3, 6, 5, 9, 7, 3, 5,\n",
       "       5, 9, 9, 8, 5, 3, 3, 2, 0, 5, 8, 3, 4, 0, 2, 4, 6, 4, 3, 4, 5, 0,\n",
       "       5, 2, 1, 3, 1, 4, 1, 1, 7, 0, 1, 5, 2, 1, 2, 8, 7, 0, 6, 4, 8, 8,\n",
       "       5, 1, 8, 4, 5, 8, 7, 9, 8, 6, 0, 6, 2, 0, 7, 9, 1, 9, 5, 2, 7, 7,\n",
       "       1, 8, 7, 4, 3, 8, 3, 5])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "y_pred_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_proba теперь возвращает массив с вероятностями каждого из 3 классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06549848e-05, 3.78505439e-07, 1.44108777e-11, ...,\n",
       "        4.43101997e-09, 3.69026377e-05, 9.65703175e-07],\n",
       "       [1.66657187e-06, 2.67049805e-10, 2.09546825e-12, ...,\n",
       "        5.05173704e-10, 2.25332334e-05, 9.84534333e-01],\n",
       "       [1.38335788e-13, 1.63979527e-08, 7.85154939e-08, ...,\n",
       "        4.34969239e-07, 9.46991487e-03, 7.97261381e-04],\n",
       "       ...,\n",
       "       [9.66304745e-06, 3.28835151e-05, 5.74549938e-05, ...,\n",
       "        2.24631195e-06, 9.99214894e-01, 3.23856703e-07],\n",
       "       [1.98567181e-07, 1.25228846e-08, 2.64750654e-04, ...,\n",
       "        8.09333153e-11, 1.71511757e-06, 1.36762966e-05],\n",
       "       [2.28383597e-07, 1.16723944e-04, 8.63343433e-11, ...,\n",
       "        1.83297543e-11, 3.10332905e-05, 6.26324563e-03]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_log_reg = log_reg.predict_proba(X_test)\n",
    "y_pred_proba_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот для KNN вообще нет разницы, два класса или больше: алгоритм работает ровно так же - выбирает самый популярный класс из $K$ соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 3, 7, 2, 1, 5, 2, 5, 2, 1, 9, 4, 0, 4, 2, 3, 7, 8, 8, 4, 3,\n",
       "       9, 7, 5, 6, 3, 5, 6, 3, 4, 9, 1, 4, 4, 6, 9, 4, 7, 6, 6, 9, 1, 3,\n",
       "       6, 1, 3, 0, 6, 5, 5, 1, 9, 5, 6, 0, 9, 0, 0, 1, 0, 4, 5, 2, 4, 5,\n",
       "       7, 0, 7, 5, 9, 9, 5, 4, 7, 0, 4, 5, 5, 9, 9, 0, 2, 3, 8, 0, 6, 4,\n",
       "       4, 9, 1, 2, 8, 3, 5, 2, 9, 0, 4, 4, 4, 3, 5, 3, 1, 3, 5, 9, 4, 2,\n",
       "       7, 7, 4, 4, 1, 9, 2, 7, 8, 7, 2, 6, 9, 4, 0, 7, 2, 7, 5, 8, 7, 5,\n",
       "       7, 9, 0, 6, 6, 4, 2, 8, 0, 9, 4, 6, 9, 9, 6, 9, 0, 3, 5, 6, 6, 0,\n",
       "       6, 4, 3, 9, 3, 4, 7, 2, 9, 0, 4, 5, 3, 6, 5, 9, 9, 8, 4, 2, 1, 3,\n",
       "       7, 7, 2, 2, 3, 9, 8, 0, 3, 2, 2, 5, 6, 9, 9, 4, 1, 5, 4, 2, 3, 6,\n",
       "       4, 8, 5, 9, 5, 7, 8, 9, 4, 8, 1, 5, 4, 4, 9, 6, 1, 8, 6, 0, 4, 5,\n",
       "       2, 7, 4, 6, 4, 5, 6, 0, 3, 2, 3, 6, 7, 1, 5, 1, 4, 7, 6, 8, 8, 5,\n",
       "       5, 1, 6, 2, 8, 8, 9, 5, 7, 6, 2, 2, 2, 3, 4, 8, 8, 3, 6, 0, 9, 7,\n",
       "       7, 0, 1, 0, 4, 5, 1, 5, 3, 6, 0, 4, 1, 0, 0, 3, 6, 5, 9, 7, 3, 5,\n",
       "       5, 9, 9, 8, 5, 3, 3, 2, 0, 5, 8, 3, 4, 0, 2, 4, 6, 4, 3, 4, 5, 0,\n",
       "       5, 2, 1, 3, 1, 4, 1, 1, 7, 0, 1, 5, 2, 1, 2, 8, 7, 0, 6, 4, 8, 8,\n",
       "       5, 1, 8, 4, 5, 8, 7, 9, 8, 6, 0, 6, 2, 0, 7, 9, 8, 9, 5, 2, 7, 7,\n",
       "       1, 8, 7, 4, 3, 8, 3, 5])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_knn = knn.predict_proba(X_test)\n",
    "y_pred_proba_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n",
      "0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred_log_reg))\n",
    "print(accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика Accuracy - одна из немногих, которая легко переносится с бинарной классификации на небинарную. Это все еще просто доля объектов с верно угаданным классами.\n",
    "\n",
    "Как мы видим, обе известные нам модели работают на цифрах очень и очень круто, учитывая что там 10 сбалансированных классов, а они угадывают больше 96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот с другими метриками возникают проблемы - неочевидно как обобщить их на несколько классов. Обычно есть два способа это сделать.\n",
    "\n",
    "- macro - это аналог One vs The Rest, метрика просто считается для каждого класса независимо, а потом усредняется\n",
    "\n",
    "- micro - это более сложная вещь, здесь нужно рассмотреть каждую пару \"объект, класс\" как объекты, и как будто считать метрики на бинарной классификации в этой задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9605024983955005\n",
      "0.9879206496042758\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(precision_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n",
      "0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_pred_log_reg, average='micro'))\n",
    "print(precision_score(y_test, y_pred_knn, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9624192637276927\n",
      "0.9878035043804756\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(recall_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9611111111111111\n",
      "0.9861111111111112\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_test, y_pred_log_reg, average='micro'))\n",
    "print(recall_score(y_test, y_pred_knn, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9609438803307118\n",
      "0.9877979367135244\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(f1_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9609438803307118\n",
      "0.9877979367135244\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_pred_log_reg, average='macro'))\n",
    "print(f1_score(y_test, y_pred_knn, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, на этом датасете везде получается одно и то же ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}